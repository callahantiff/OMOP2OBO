{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "***\n",
    "\n",
    "<img width=\"220\" align=\"right\" alt=\"Screen Shot 2020-10-14 at 20 48 36\" src=\"https://user-images.githubusercontent.com/8030363/96071102-ae5d5900-0e5e-11eb-99e3-c39e4fb4f1b6.png\">\n",
    "\n",
    "\n",
    "# OMOP2OBO\n",
    "\n",
    "### *Ontologizing Health Systems at Scale: Making Translational Discovery a Reality*\n",
    "\n",
    "<br>\n",
    "\n",
    "**Author:** [TJCallahan](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=callahantiff@gmail.com)  \n",
    "**GitHub Repository:** [OMOP2OBO](https://github.com/callahantiff/OMOP2OBO/wiki)  \n",
    "**Current Release:** **[`V1.0`](https://github.com/callahantiff/OMOP2OBO/wiki/v1.0)**\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "**Project Goals:** Common data models have solved many challenges of utilizing electronic health records, but have not yet meaningfully integrated clinical and molecular data. Aligning clinical data to open biological ontologies (OBOs), which provide semantically computable representations of biological knowledge, requires extensive manual curation and expertise. To address these limitations, we introduce OMOP2OBO, a health system-scale, disease-agnostic methodology to create interoperability between standardized clinical terminologies and semantically encoded OBOs and present results demonstrating the utility within two health systems.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Purpose\n",
    "\n",
    "This notebook serves as a `main` file for the `OMOP2OBO` project. This scripts walks through this program step-by-step and generates mappings between Observational Medical Outcomes Partnership (OMOP) common data model and ontologies in the Open Biological and Biomedical Ontologies (OBO) Foundry. There is also a command line version of this file ([`main.py`](https://github.com/callahantiff/OMOP2OBO/blob/master/main.py)). Please see the [README](https://github.com/callahantiff/OMOP2OBO) for more information.\n",
    "\n",
    "**OMOP2OBO Workflow**  \n",
    "The figure below provides a high-level overview of the `OMOP2OBO` mapping algorithm. The steps code in this notebook aligns to the steps shown in this figure. The only step that is not run is querying an OMOP instance. Since it is highly likely that these instance contain patient data, we assume that data has already been obtained and saved in the `resources/clinical_data/` repository. See project [README](https://github.com/callahantiff/OMOP2OBO) for additional information.\n",
    "\n",
    "<img width=\"2000\" alt=\"Screen Shot 2020-09-20 at 22 59 00\" src=\"https://user-images.githubusercontent.com/8030363/96070809-25462200-0e5e-11eb-88ba-2a30c3e8dab0.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "### Assumptions    \n",
    "Please make sure that the following dependencies are addressed before running this notebook:\n",
    "\n",
    "- [x] **OWLTools**. This software also relies on [OWLTools](https://github.com/owlcollab/owltools). If cloning the repository, the owltools library file will automatically be included and placed in the correct repository.\n",
    "- [x] **Clinical Data**. This program assumes that there is clinical data that needs mapping and it has been placed in the `resources/clinical_data` repository. Each data source provided in this repository is assumed to extracted from the `OMOP` CDM. An example of what is expected for input clinical data can be found [`here`](https://github.com/callahantiff/OMOP2OBO/tree/master/resources/clinical_data).  \n",
    "- [x] **UMLS Data**. This program depends on data from the National of Library Medicine's Unified Medical Language System (UMLS), specifically the [MRCONSO.RRF](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html) and [MRSTY.RRF](https://www.ncbi.nlm.nih.gov/books/NBK9685/table/ch03.Tf/) files. Please note, using these data requires a license agreement. Note that in order to get the `MRSTY.RRF` file you will need to download the UMLS Metathesaurus and run `MetamorphoSys`. Once both data sources are obtained, please place each file in the `resources/mappings` directory.\n",
    "- [x] **Ontology Data:** Ontology data is automatically downloaded from the user provided input file `ontology_source_list.txt`. Please fill update this information ([here](https://github.com/callahantiff/OMOP2OBO/blob/master/resources/ontology_source_list.txt)).\n",
    "- [x] **Vocabulary Source Code Mapping**. To increase the likelihood of capturing existing database cross-references, `omop2obo` provides a file that maps different clinical vocabulary source code prefixes between the `UMLS`, OBO ontologies, and clinical data. This information is stored in the  `source_code_vocab_map.csv` ([here](https://github.com/callahantiff/OMOP2OBO/blob/master/resources/mappings/source_code_vocab_map.csv)). The current version of this file is updated for ontologies released September 2020, clinical data normalized to `OMOP_v5.0`, and UMLS `2020AA`. \n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "### Table of Contents\n",
    "***\n",
    "The three primary steps involved in mapping OMOP CDM concepts to OBO ontologies are: `Exact Mappings`, `Fuzzy Mappings`, and `Aggregate Mapping Results`.\n",
    "\n",
    "* [Download Ontology Data](#download-ontologies)  \n",
    "* [Generate Mappings](#mappings)  \n",
    "* [Aggregate Mapping Results](#aggregate-mapping-results)  \n",
    "\n",
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import click\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from datetime import date, datetime\n",
    "from typing import Tuple\n",
    "\n",
    "from omop2obo import ConceptAnnotator, OntologyDownloader, OntologyInfoExtractor, SimilarStringFinder\n",
    "from omop2obo.utils import aggregates_mapping_results\n",
    "\n",
    "# set time-stamped var for writing output to\n",
    "date_today = '_' + datetime.strftime(datetime.strptime(str(date.today()), '%Y-%m-%d'), '%d%b%Y').upper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Download Ontologies <a class=\"anchor\" id=\"download-ontologies\"></a>\n",
    "***\n",
    "\n",
    "The purpose of this step is to download the needed OBO ontologies, process them, and output a master dictionary of processed ontology data. The `V1.0` release parses the following OBO ontologies for each specific clinical domain: \n",
    "\n",
    "Ontology | Clinical Domain \n",
    ":--: | :--:\n",
    "[Human Phenotype Ontology (hp)](http://purl.obolibrary.org/obo/hp.owl) | Conditions; Measurements      \n",
    "[Mondo Disease Ontology (mondo)](http://purl.obolibrary.org/obo/mondo.owl) | Conditions      \n",
    "[Cell Ontology (cl)](http://purl.obolibrary.org/obo/cl.owl) | Measurements        \n",
    "[Chemical Entities of Biological Interest (chebi)](http://purl.obolibrary.org/obo/chebi.owl) | Measurements; Drugs        \n",
    "[NCBI Organism Taxonomy (ncbitaxon)](http://purl.obolibrary.org/obo/ncbitaxon.owl) | Measurements; Drugs     \n",
    "[Protein Ontology (pr)](http://purl.obolibrary.org/obo/pr.owl) | Measurements; Drugs     \n",
    "[Uber Anatomy Ontology (uberon)](http://purl.obolibrary.org/obo/uberon/ext.owl) | Measurements       \n",
    "[Vaccine Ontology (vo)](http://purl.obolibrary.org/obo/vo.owl) | Drugs  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Input File:** [`ontology_source_list.txt`](https://github.com/callahantiff/OMOP2OBO/blob/master/resources/ontology_source_list.txt)  \n",
    "\n",
    "**Purpose:**\n",
    "This step of the algorithm is designed to complete the following steps:  \n",
    "1. [Download OBO Ontology Data](#download-data)  \n",
    "2. [Process Ontologies](#process-ontologies)   \n",
    "3. [Create Master Ontology Dictionary](#master-ont-dict)  \n",
    "\n",
    "<br>\n",
    "\n",
    "*NOTE.* All data from the current release, except for UMLS data, can be downloaded directly from the project Wiki in the current release sub-page.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Download OBO Ontologies <a class=\"anchor\" id=\"download-data\"></a>\n",
    "This step downloads each `OBO` ontology in the `ontology_source_list.txt` file using the [OWLTools](https://github.com/owlcollab/owltools) API.\n",
    "\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/ontologies/` repository.\n",
    "- `ontology_source_metadata.txt`: a file containing metadata on each downloaded\n",
    "- An `.owl` file will be downloaded for each ontology in `ontology_source_list.txt`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download ontologies\n",
    "ont = OntologyDownloader('resources/ontology_source_list.txt')\n",
    "ont.downloads_data_from_url()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Process OBO Ontologies <a class=\"anchor\" id=\"process-ontologies\"></a>\n",
    "This step processes each of the downloaded ontologies to obtain the following information for all non-deprecated classes: definitions, labels, synonyms, and database Cross-References (DbxRefs). An example of the output for the Cell Ontology is shown below:  \n",
    "\n",
    "```\n",
    "{'label': {'osteoclast': 'http://purl.obolibrary.org/obo/CL_0000092'},\n",
    " 'definition': {'a plasmablast that secretes ige.': 'http://purl.obolibrary.org/obo/CL_0000950'},\n",
    " 'dbxref': {'bto:0001173': 'http://purl.obolibrary.org/obo/CL_0000558'},\n",
    " 'dbxref_type': {'bto:0001173': 'DbXref'},\n",
    " 'synonym': {'multipotent cell': 'http://purl.obolibrary.org/obo/CL_0000048'},\n",
    " 'synonym_type': {'multipotent cell': 'hasExactSynonym'} \n",
    " }\n",
    "```     \n",
    "\n",
    "<br>\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/ontologies/` repository.   \n",
    "- A `.pickle` file for each ontology containing processed ontology content (i.e. non-deprecated classes, labels, definitions, synonyms, and dbxrefs) will be downloaded  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process ontologies\n",
    "ont_explorer = OntologyInfoExtractor('resources/ontologies', ont.data_files)\n",
    "ont_explorer.ontology_processor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Create Master Ontology Dictionary <a class=\"anchor\" id=\"master-ont-dict\"></a>\n",
    "This step parses each of the processed ontology files from the prior step and merges them all into a single nested ontology dictionary. The primary keys to the dictionary are identifiers for each ontology (e.g. `hp`, `mondo`, `chebi`) and each ontologies sub-dictionary contains the following keys: `label`, `definition`, `dbxref`, `dbxref_type`, `synonym`, and `synonym_type`.\n",
    "\n",
    "For release `V1.0` this step generates the following results:  \n",
    "\n",
    "Ontology | Classes | Definitions | Labels | Synonyms | DbXRefs  \n",
    ":--: | :--: | :--: | :--: | :--: | :--:  \n",
    "Human Phenotype Ontology (hp) | 15,247 | 12,468 | 15,247 | 19,860 | 19,569  \n",
    "Mondo Disease Ontology (mondo) | 22,288 | 15,271 | 22,288 | 98,181 | 159,918  \n",
    "Cell Ontology (cl) | 2,238 | 1,859 | 2,238 | 2,124 | 1,376  \n",
    "Chemical Entities of Biological Interest (chebi) | 126,169 | 48,824 | 126,169 | 269,798 | 231,247\n",
    "NCBI Organism Taxonomy (ncbitaxon) | 2,241,110 | 0 | 2,241,110 | 263,571 | 18,426. \n",
    "Protein Ontology (pr) | 215,624 | 215,598 | 215,624 | 590,190 | 195,671\n",
    "Uber Anatomy Ontology (uberon) | 13,898 | 11,026 | 13,898 | 36,771 | 51,322  \n",
    "Vaccine Ontology (vo) | 5,783 | 1,231 | 5,783 | 6 | 0   \t\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/ontologies/` repository.  \n",
    "- `master_ontology_dictionary.pickle`: a file containing the processed ontology content formatted as a dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create master dictionary of processed ontologies\n",
    "ont_explorer.ontology_loader()\n",
    "\n",
    "# read in ontology data\n",
    "with open('resources/ontologies/master_ontology_dictionary.pickle', 'rb') as handle:\n",
    "    ont_data = pickle.load(handle)\n",
    "handle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate table in heading\n",
    "for key in ont_data.keys():\n",
    "    print('\\nProcessing Ontology {}'.format(key))\n",
    "    print('# classes: {}'.format(len(set([v for k, v in ont_data[key]['label'].items()]))))\n",
    "    print('# definitions: {}'.format(len(set(ont_data[key]['definition']))))\n",
    "    print('# labels: {}'.format(len(set(ont_data[key]['label']))))\n",
    "    print('# synonyms: {}'.format(len(set(ont_data[key]['synonym']))))\n",
    "    print('# dbXRefs: {}'.format(len(set(ont_data[key]['dbxref']))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "***\n",
    "## Generate Mappings <a class=\"anchor\" id=\"mappings\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:**\n",
    "This step of the algorithm is designed to complete the following steps to generate mappings:  \n",
    "1. [Generate Exact Mappings](#exact-map)  \n",
    "2. [Generate Fuzzy Mappings](#fuzzy-map)    \n",
    "\n",
    "<br>\n",
    "\n",
    "**Input Files:**\n",
    "- `clinical_data`: Clinical data from the OMOP common data model needing mapping  \n",
    "- `resources/mappings/MRCONSO.RRF`:  UMLS CUI information and mappings    \n",
    "- `resources/mappings/MRSTY.RRF`: UMLS Semantic Types     \n",
    "- `source_code_vocab_map.csv`: A file containing information for normalizing \n",
    "\n",
    "The current release (`V2.0`) maps concepts for `29,129` condition concepts, `1,697` drug exposure ingredients, and `4,083` measurements.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example Clinical and ONtology Input Data**  \n",
    "\n",
    "<img width=\"700\" alt=\"Screen Shot 2020-09-20 at 22 26 23\" src=\"https://user-images.githubusercontent.com/8030363/93732838-5c435380-fb90-11ea-913c-ed2546a565ba.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<br> \n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/mappings/` repository.  \n",
    "- A `.csv` file containing mapping results for each processed clinical file     \n",
    "\n",
    "<br>\n",
    "\n",
    "*NOTE.* All data from the current release, except for UMLS data, can be downloaded directly from the project Wiki in the current release sub-page.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Generate Exact Mappings <a class=\"anchor\" id=\"exact-map\"></a>  \n",
    "This step performs exact mapping using clinical-ontology dbXRefs and by looking for exact matches between clinical code and ontology class labels and synonyms. This task is performed in the following steps at the OMOP `concept` and `ancestor` levels:  \n",
    "1. Merge OMOP `source_codes` to UMLS `SAB` codes and then re-merge omop-merged CUIs to UMLS CUIs to obtain additional source code mappings  \n",
    "2. Map OMOP `source_code` to ontology `dbXRef` codes  \n",
    "3. Exact match OMOP concept labels and synonyms to ontology labels and synonyms\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/mappings/` repository.  \n",
    "- A `.csv` file containing mapping results for each processed clinical file  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Input Parameters**  \n",
    "Uncomment each clinical domain chunk and process them separately. \n",
    "- If you have an OMOP database instance and want to obtain concepts to map, you can run the queries we make available as a GitHub Gist [here](https://gist.github.com/callahantiff/7b84c1bc063ad162bf5bdf5e578d402f).  \n",
    "- If you have your clinical OMOP data in a Google Cloud Storage Bucket, you can use the [`google_cloud_storage_downloader.py`](https://github.com/callahantiff/OMOP2OBO/blob/master/google_cloud_storage_downloader.py) script to automatically download it into your project repository.\n",
    "\n",
    "<br>\n",
    "\n",
    "**The OMOP2OBO Parameters Include:**  \n",
    "- `clinical_data`: A Pandas DataFrame containing clinical data.\n",
    "- `ontology_dictionary`: A nested dictionary containing ontology data, where outer keys are ontology identifiers\n",
    "    (e.g. \"hp\", \"mondo\"), inner keys are data types (e.g. \"label\", \"definition\", \"dbxref\", and \"synonyms\").\n",
    "    - For each inner key, there is a third dictionary keyed by a string of that item type and with values that\n",
    "    are the ontology URI for that string type.\n",
    "- `primary_key`: A string containing the column name of the primary key.\n",
    "- `concept_codes`: A list of column names containing concept-level codes (optional).\n",
    "- `concept_strings`: A list of column names containing concept-level labels and synonyms (optional).\n",
    "- `ancestor_codes`: A list of column names containing ancestor concept-level codes (optional).\n",
    "- `ancestor_strings`: A list of column names containing ancestor concept-level labels and synonyms (optional).\n",
    "- `umls_cui_data`: A Pandas DataFrame containing UMLS CUI data from MRCONSO.RRF.\n",
    "- `umls_tui_data`: A Pandas DataFrame containing UMLS CUI data from MRSTY.RRF.\n",
    "- `source_code_map`: A dictionary containing clinical vocabulary source code abbreviations.\n",
    "- `umls_double_merge`: A `bool` specifying whether to merge UMLS SAB codes with OMOP source codes once or twice.\n",
    "    - Merging once will only align OMOP source codes to UMLS SAB  \n",
    "    - Merging twice with take the CUIs from merging once and merge them again with the full UMLS SAB set resulting in a larger set of matches. The default value is `True`, which means that the merge will be performed twice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a clinical domain to run ('CONDITIONS', 'DRUGS', or 'LABS')\n",
    "clinical_domain = 'CONDITIONS'\n",
    "\n",
    "# point to clinical data\n",
    "clinical_data = 'file path to data.csv'\n",
    "\n",
    "# set umls merge type\n",
    "umls_merge_type = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clinical_domain == 'CONDITIONS':\n",
    "    onts = ['hp', 'mondo']\n",
    "    primary_key = 'CONCEPT_ID'\n",
    "    concept_codes = tuple(['CONCEPT_SOURCE_CODE'])\n",
    "    concept_strings = tuple(['CONCEPT_SOURCE_LABEL', 'CONCEPT_SYNONYM'])\n",
    "    ancestor_codes = tuple(['ANCESTOR_SOURCE_CODE'])\n",
    "    ancestor_strings = tuple(['ANCESTOR_LABEL'])\n",
    "    outfile = 'resources/mappings/condition_codes/OMOP2OBO_MAPPED_'\n",
    "elif clinical_domain = 'DRUGS':\n",
    "    onts = ['chebi', 'pr', 'ncbitaxon', 'vo']\n",
    "    primary_key = 'INGREDIENT_CONCEPT_ID'\n",
    "    concept_codes = tuple(['INGREDIENT_SOURCE_CODE'])\n",
    "    concept_strings = tuple(['INGREDIENT_LABEL', 'INGREDIENT_SYNONYM'])\n",
    "    ancestor_codes = tuple(['INGRED_ANCESTOR_SOURCE_CODE'])\n",
    "    ancestor_strings = tuple(['INGRED_ANCESTOR_LABEL'])\n",
    "    outfile = 'resources/mappings/medication_codes/OMOP2OBO_MAPPED_'\n",
    "else:\n",
    "    onts = ['hp', 'uberon', 'cl', 'chebi', 'pr', 'ncbitaxon']\n",
    "    primary_key = 'CONCEPT_ID'\n",
    "    concept_codes = tuple(['CONCEPT_SOURCE_CODE'])\n",
    "    concept_strings = tuple(['CONCEPT_LABEL', 'CONCEPT_SYNONYM'])\n",
    "    ancestor_codes = tuple(['ANCESTOR_SOURCE_CODE'])\n",
    "    ancestor_strings = tuple(['ANCESTOR_LABEL'])\n",
    "    outfile = 'resources/mappings/laboratory_tests/OMOP2OBO_MAPPED_'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Exact Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = ConceptAnnotator(clinical_file=clinical_data,\n",
    "                          ontology_dictionary={k: v for k, v in ont_data.items() if k in onts},\n",
    "                          umls_expand=umls_merge_type,\n",
    "                          primary_key=primary_key,\n",
    "                          concept_codes=concept_codes,\n",
    "                          concept_strings=concept_strings,\n",
    "                          ancestor_codes=ancestor_codes,\n",
    "                          ancestor_strings=ancestor_strings,\n",
    "                          umls_mrconso_file=glob.glob('resources/mappings/*MRCONSO*')[0]\n",
    "                          if len(glob.glob('resources/mappings/*MRCONSO*')) > 0 else None,\n",
    "                          umls_mrsty_file=glob.glob('resources/mappings/*MRSTY*')[0]\n",
    "                          if len(glob.glob('resources/mappings/*MRSTY*')) > 0 else None)\n",
    "\n",
    "mappings = mapper.clinical_concept_mapper()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSaving Results: {}'.format('Exact Match'))\n",
    "mappings.to_csv(outfile + clinical_domain.upper() + date_today + '.csv', sep=',', index=False, header=True)\n",
    "\n",
    "# get column names -- used later to organize output\n",
    "start_cols = [i for i in mappings.columns if not any(j for j in ['STR', 'DBXREF', 'EVIDENCE'] if j in i)]\n",
    "exact_cols = [i for i in mappings.columns if i not in start_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Generate Fuzzy Mappings <a class=\"anchor\" id=\"fuzzy-map\"></a> \n",
    "This step builds a Term Frequency-Inverse Document Frequency (TF-IDF)-weighted Bag-of-Words model and uses it to identify mappings between the OMOP clinical concepts and ontology terms. To build this model, clinical labels and synonyms are processed along with ontology labels, definitions, and synonyms. Only those matches between clinical concepts and ontology terms with a score `>=0.2` are exported.  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/mappings/` repository.  \n",
    "- A `.csv` file containing mapping results for each processed clinical file  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tfidf_mapping is not None:\n",
    "    sim = SimilarStringFinder(clinical_file=outfile + clinical_domain.upper() + date_today + '.csv',\n",
    "                              ontology_dictionary={k: v for k, v in ont_data.items() if k in onts},\n",
    "                              primary_key=primary_key,\n",
    "                              concept_strings=concept_strings)\n",
    "\n",
    "    sim_mappings = sim.performs_similarity_search()\n",
    "    \n",
    "    # get column names -- used later to organize output\n",
    "    sim_mappings = sim_mappings[[primary_key] + [x for x in sim_mappings.columns if 'SIM' in x]].drop_duplicates()\n",
    "    sim_cols = [i for i in sim_mappings.columns if not any(j for j in start_cols if j in i)]\n",
    "\n",
    "    # merge dbXref, exact string, and TF-IDF similarity results\n",
    "    merged_scores = pd.merge(mappings, sim_mappings, how='left', on=primary_key)\n",
    "    mappings = merged_scores[start_cols + exact_cols + sim_cols]\n",
    "\n",
    "    print('\\nSaving Results: {}'.format('TF-IDF Cosine Similarity'))\n",
    "    mappings.to_csv(outfile + clinical_domain.upper() + date_today + '.csv', sep=',', index=False, header=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "***\n",
    "## Aggregate Mapping Results<a class=\"anchor\" id=\"aggregate-mapping-results\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:**\n",
    "This step is designed to compile and aggregate the mapping results from running the exact and fuzzy mapping steps. The goal is to parse all of the results for a given clinical domain and each utilized ontology and return a single result (i.e. `ontology uri`, `ontology label`, `mapping category`, and `mapping evidence`). An example of the mapping categories and a mapping result for `OMOP_` (Apraxia) is shown below:\n",
    "<img width=\"750\" alt=\"Screen Shot 2020-09-20 at 22 37 23\" src=\"https://user-images.githubusercontent.com/8030363/93733253-efc95400-fb91-11ea-8a61-a614113bd7eb.png\">\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Input Files:** A `.csv` file output from running `omop2obo` to obtain exact and fuzzy mappings. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Output Files:**  \n",
    "The following content will be downloaded to the `resources/mappings/` repository.  \n",
    "- A `.csv` file containing mapping results for each processed clinical file  \n",
    "\n",
    "<br>\n",
    "\n",
    "*NOTE.* All data from the current release, except for UMLS data, can be downloaded directly from the project Wiki in the current release sub-page.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up output\n",
    "if clinical_domain == 'LABS':\n",
    "    result_type_idx, updated_data = list(mappings.columns).index('RESULT_TYPE'), []\n",
    "    for idx, row in mappings.iterrows():\n",
    "        if row['RESULT_TYPE'] == 'Normal/Low/High' or row['RESULT_TYPE'] == 'Negative/Positive':\n",
    "            for x in row['RESULT_TYPE'].split('/'):\n",
    "                updated = list(row)\n",
    "                updated[result_type_idx] = x\n",
    "                updated_data.append(updated)\n",
    "        else:\n",
    "            updated_data.append(list(row))\n",
    "\n",
    "    # replace values\n",
    "    data_expanded = pd.DataFrame(updated_data, columns=list(mappings.columns))\n",
    "else:\n",
    "    data_expanded = mappings.copy()\n",
    "data_expanded.fillna('', inplace=True)\n",
    "\n",
    "# aggregate mapping evidence\n",
    "updated_mappings = aggregates_mapping_results(data_expanded, onts, ont_data, mapper.source_code_map, 0.25)\n",
    "updated_mappings.to_csv(outfile + clinical_domain.upper() + date_today + '.csv', sep=',', index=False, header=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
